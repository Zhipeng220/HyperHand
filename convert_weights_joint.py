import torch

# --- 1. ä¿®æ”¹é…ç½® ---
# ğŸ”´ æŒ‡å‘æ‚¨æ–°çš„â€œå…³èŠ‚ç‚¹â€æœ€ä½³æ¨¡å‹
original_file = 'work_dir/egogesture/aimclr_pretext_joint/epoch070_acc32.54_model.pt'

# ğŸ”´ æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªæ–°çš„â€œå…³èŠ‚ç‚¹â€éª¨å¹²æ–‡ä»¶
new_file = 'work_dir/egogesture/aimclr_pretext_joint/epoch070_JOINT_BACKBONE_ONLY.pt'
prefix_to_remove = 'encoder_q.'
# ---------------------

print(f"Loading weights from: {original_file}")
full_checkpoint = torch.load(original_file, map_location='cpu')

new_state_dict = {}

# å¾ªç¯æ‰€æœ‰æƒé‡
for key, value in full_checkpoint.items():

    # ä¿æŒæˆ‘ä»¬çš„ä¿®å¤ï¼šåªä¿å­˜éª¨å¹²ç½‘ç»œ (encoder_q)ï¼Œå¹¶ä¸¢å¼ƒé¢„è®­ç»ƒå¤´ (fc)
    if key.startswith(prefix_to_remove) and not key.startswith("encoder_q.fc."):

        # ç§»é™¤ "encoder_q." å‰ç¼€
        new_key = key.replace(prefix_to_remove, "")

        new_state_dict[new_key] = value
        print(f"Converting: {key}  --->  {new_key}")

print("\nAll other keys (encoder_k, queue, fc) successfully ignored.")

# ä¿å­˜æ–°çš„æ–‡ä»¶
torch.save(new_state_dict, new_file)
print(f"\nâœ… Success! JOINT backbone weights saved to: {new_file}")